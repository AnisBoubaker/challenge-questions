# Challenge Questions Generator

This repository contains datasets, python scripts code and generated results of the project challenge-questions generator. This project aims at detecting learning gaps in student-submitted code by generating automated challenge questions. The proposed method compares the abstract syntax trees (ASTs) of student code with those of class-taught examples using embeddings and retrieval-augmented generation (RAG). The approach identifies the most structurally deviant sections of student code and generates challenge questions targeting advanced, un-taught coding techniques, such as function pointers and variadic functions. The evaluation, conducted on real-world C programming assignments, demonstrates the effectiveness of the selection process and the quality of generated questions. This work highlights the potential for using structural analysis and automated feedback to improve student assessment in coding education. 

## Code organization
The code of this repository is organized as follows: 
* The data directory contains initial student submissions data.
* Corpus directory contains code examples used during the programming course.
* The scripts directory contains the scripts used to gnerate challenge questions, prefixed by the order in which they are used:
  *  0_data_cleanup: textual cleanup that removes comments and pre-processos directives.
  *  1_parse_code: Generates ASTs from student submissions and course examples using pycparser.
  *  2_generate_corpus_embeddings: Creates a ChromaDB database of embeddings of code examples. The examples are obtained through OpenAI's API.
  *  3_compute_similarities: For each function from a student submitted project, this script generates the vector embedding and selects the 5 top similar functions from code examples (stored in the ChromaDB).
  *  4_select_cadidates: Given all the functions of a student submission, along with all selected similar code examples, this script selects those function with the highest distance from code examples.
  *  5_generate_questions: From all selected candidates, this script interact with OpenAI's completions API asking to generate a question on a specific student function, proving it with closest code examples. 5_system_prompt.txt includes the system promp used in these requests.
* The data_questions directory contains the resulting questions, organized by student submission.
* The remaining data_??? directories contain the data generated by all intermediary operations.



